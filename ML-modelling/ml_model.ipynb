{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>round</th>\n",
       "      <th>driver_age</th>\n",
       "      <th>driver_experience</th>\n",
       "      <th>driver_constructor_experience</th>\n",
       "      <th>driver_points</th>\n",
       "      <th>driver_standing</th>\n",
       "      <th>constructor_points</th>\n",
       "      <th>...</th>\n",
       "      <th>constructorId_205</th>\n",
       "      <th>constructorId_206</th>\n",
       "      <th>constructorId_207</th>\n",
       "      <th>constructorId_208</th>\n",
       "      <th>constructorId_209</th>\n",
       "      <th>constructorId_210</th>\n",
       "      <th>constructorId_211</th>\n",
       "      <th>constructorId_213</th>\n",
       "      <th>constructorId_214</th>\n",
       "      <th>constructorId_215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>116</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid  position  year  round  driver_age  driver_experience  \\\n",
       "0     3       1.0  2010      1          28                140   \n",
       "1     2       2.0  2010      1          28                116   \n",
       "2     4       3.0  2010      1          25                 52   \n",
       "3     1       4.0  2010      1          22                 43   \n",
       "4     5       5.0  2010      1          24                 70   \n",
       "\n",
       "   driver_constructor_experience  driver_points  driver_standing  \\\n",
       "0                              0            0.0              0.0   \n",
       "1                             63            0.0              0.0   \n",
       "2                             52            0.0              0.0   \n",
       "3                             17            0.0              0.0   \n",
       "4                              0            0.0              0.0   \n",
       "\n",
       "   constructor_points  ...  constructorId_205  constructorId_206  \\\n",
       "0                 0.0  ...              False              False   \n",
       "1                 0.0  ...              False              False   \n",
       "2                 0.0  ...              False              False   \n",
       "3                 0.0  ...              False              False   \n",
       "4                 0.0  ...              False              False   \n",
       "\n",
       "   constructorId_207  constructorId_208  constructorId_209  constructorId_210  \\\n",
       "0              False              False              False              False   \n",
       "1              False              False              False              False   \n",
       "2              False              False              False              False   \n",
       "3              False              False              False              False   \n",
       "4              False              False              False              False   \n",
       "\n",
       "   constructorId_211  constructorId_213  constructorId_214  constructorId_215  \n",
       "0              False              False              False              False  \n",
       "1              False              False              False              False  \n",
       "2              False              False              False              False  \n",
       "3              False              False              False              False  \n",
       "4              False              False              False              False  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data-collection/final_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4473, Testing set size: 783\n"
     ]
    }
   ],
   "source": [
    "# Here the test data needs to be whole races, not random entries from different races\n",
    "# Will do 3 races per season as test sets\n",
    "test_races_per_year = 3\n",
    "\n",
    "# Create a train-test split based on races\n",
    "unique_races = df[['year', 'round']].drop_duplicates()\n",
    "test_races = unique_races.groupby('year').sample(n=test_races_per_year, random_state=42)\n",
    "\n",
    "# Mark test races in the dataset\n",
    "df['is_test'] = df[['year', 'round']].apply(\n",
    "    lambda x: tuple(x) in test_races.itertuples(index=False, name=None), axis=1\n",
    ")\n",
    "\n",
    "# Split the data\n",
    "train_df = df[df['is_test'] == False]\n",
    "test_df = df[df['is_test'] == True]\n",
    "\n",
    "train_df = train_df.drop(columns=['is_test'])\n",
    "test_df = test_df.drop(columns=['is_test'])\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}, Testing set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features: (4473, 146), Testing Features: (783, 146)\n",
      "Training Target: (4473,), Testing Target: (783,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.drop(columns=['position'])\n",
    "X_test = test_df.drop(columns=['position'])\n",
    "\n",
    "y_train = train_df['position']\n",
    "y_test = test_df['position']\n",
    "\n",
    "print(f\"Training Features: {X_train.shape}, Testing Features: {X_test.shape}\")\n",
    "print(f\"Training Target: {y_train.shape}, Testing Target: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numerical columns for scaling\n",
    "numerical_columns = [\n",
    "    'grid', 'driver_age', 'driver_experience', 'driver_constructor_experience',\n",
    "    'driver_points', 'driver_standing', 'constructor_points', \n",
    "    'constructor_standing', 'driver_wins', 'constructor_wins', 'circuit_danger', \n",
    "    'year', 'round'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "\n",
    "# conver one-hot-encoding columns from True/False to 1/0\n",
    "all_columns = X_train.columns.tolist()\n",
    "one_hot_columns = [col for col in all_columns if col not in numerical_columns]\n",
    "\n",
    "X_train[one_hot_columns] = X_train[one_hot_columns].astype(int)\n",
    "X_test[one_hot_columns] = X_test[one_hot_columns].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg_lr_model = LinearRegression()\n",
    "reg_lr_model.fit(X_train, y_train)\n",
    "reg_lr_y_test = reg_lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg_rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "reg_rf_model.fit(X_train, y_train)\n",
    "reg_rf_y_test = reg_rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "reg_svm_model = SVR(kernel='linear') \n",
    "reg_svm_model.fit(X_train, y_train)\n",
    "reg_svm_y_test = reg_svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "reg_dt_model = DecisionTreeRegressor()\n",
    "reg_dt_model.fit(X_train, y_train)\n",
    "reg_dt_y_test = reg_dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "reg_knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "reg_knn_model.fit(X_train, y_train)\n",
    "reg_knn_y_test = reg_knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "reg_lasso_model = Lasso(alpha=0.1) \n",
    "reg_lasso_model.fit(X_train, y_train)\n",
    "reg_lasso_y_test = reg_lasso_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Linear Regression ----\n",
      " MAE: 2.31\n",
      " RMSE: 9.25\n",
      " R2: 0.67\n",
      "\n",
      "---- Random Forest ----\n",
      " MAE: 2.22\n",
      " RMSE: 8.82\n",
      " R2: 0.69\n",
      "\n",
      "---- SVM ----\n",
      " MAE: 2.26\n",
      " RMSE: 9.51\n",
      " R2: 0.66\n",
      "\n",
      "---- Decision Tree ----\n",
      " MAE: 2.98\n",
      " RMSE: 16.78\n",
      " R2: 0.41\n",
      "\n",
      "---- KNN ----\n",
      " MAE: 2.43\n",
      " RMSE: 10.24\n",
      " R2: 0.64\n",
      "\n",
      "---- Lasso ----\n",
      " MAE: 2.43\n",
      " RMSE: 10.07\n",
      " R2: 0.65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "reg_models_info = [\n",
    "    (\"Linear Regression\", \"reg_lr_y_test\"),\n",
    "    (\"Random Forest\", \"reg_rf_y_test\"),\n",
    "    (\"SVM\", \"reg_svm_y_test\"),\n",
    "    (\"Decision Tree\", \"reg_dt_y_test\"),\n",
    "    (\"KNN\", \"reg_knn_y_test\"),\n",
    "    (\"Lasso\", \"reg_lasso_y_test\")\n",
    "]\n",
    "\n",
    "for model_name, y_test_var_name in reg_models_info:\n",
    "    y_test_var = globals()[y_test_var_name]\n",
    "\n",
    "    model_test_mae = mean_absolute_error(y_test, y_test_var)\n",
    "    model_test_rmse = mean_squared_error(y_test, y_test_var)\n",
    "    model_test_r2 = r2_score(y_test, y_test_var)\n",
    "\n",
    "    print(f\"---- {model_name} ----\")\n",
    "    print(f\" MAE: {model_test_mae:.2f}\")\n",
    "    print(f\" RMSE: {model_test_rmse:.2f}\")\n",
    "    print(f\" R2: {model_test_r2:.2f}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_c = y_train.copy()\n",
    "y_test_c = y_test.copy()\n",
    "y_train_c = y_train_c.apply(lambda x: 1 if x == 1 else 0)\n",
    "y_test_c = y_test_c.apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "cla_lr_model = LogisticRegression()\n",
    "cla_lr_model.fit(X_train, y_train_c)\n",
    "cla_lr_y_test = cla_lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "cla_dt_model = DecisionTreeClassifier()\n",
    "cla_dt_model.fit(X_train, y_train_c)\n",
    "cla_dt_y_test = cla_dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "cla_svm_model = SVC(kernel='linear')\n",
    "cla_svm_model.fit(X_train, y_train_c)\n",
    "cla_svm_y_test = cla_svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "cla_rf_model = RandomForestClassifier(n_estimators=100)\n",
    "cla_rf_model.fit(X_train, y_train_c)\n",
    "cla_rf_y_test = cla_rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "cla_knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "cla_knn_model.fit(X_train, y_train_c)\n",
    "cla_knn_y_test = cla_knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "cla_nb_model = GaussianNB()\n",
    "cla_nb_model.fit(X_train, y_train_c)\n",
    "cla_nb_y_test = cla_nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Logistic Regression ----\n",
      "Accuracy: 0.9425287356321839\n",
      "Confusion Matrix:\n",
      "[[726  12]\n",
      " [ 33  12]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       738\n",
      "           1       0.50      0.27      0.35        45\n",
      "\n",
      "    accuracy                           0.94       783\n",
      "   macro avg       0.73      0.63      0.66       783\n",
      "weighted avg       0.93      0.94      0.93       783\n",
      "\n",
      "\n",
      "---- Decision Tree ----\n",
      "Accuracy: 0.9220945083014048\n",
      "Confusion Matrix:\n",
      "[[706  32]\n",
      " [ 29  16]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       738\n",
      "           1       0.33      0.36      0.34        45\n",
      "\n",
      "    accuracy                           0.92       783\n",
      "   macro avg       0.65      0.66      0.65       783\n",
      "weighted avg       0.92      0.92      0.92       783\n",
      "\n",
      "\n",
      "---- SVM ----\n",
      "Accuracy: 0.9412515964240102\n",
      "Confusion Matrix:\n",
      "[[724  14]\n",
      " [ 32  13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       738\n",
      "           1       0.48      0.29      0.36        45\n",
      "\n",
      "    accuracy                           0.94       783\n",
      "   macro avg       0.72      0.63      0.67       783\n",
      "weighted avg       0.93      0.94      0.93       783\n",
      "\n",
      "\n",
      "---- Random Forest ----\n",
      "Accuracy: 0.946360153256705\n",
      "Confusion Matrix:\n",
      "[[728  10]\n",
      " [ 32  13]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       738\n",
      "           1       0.57      0.29      0.38        45\n",
      "\n",
      "    accuracy                           0.95       783\n",
      "   macro avg       0.76      0.64      0.68       783\n",
      "weighted avg       0.94      0.95      0.94       783\n",
      "\n",
      "\n",
      "---- KNN ----\n",
      "Accuracy: 0.9476372924648787\n",
      "Confusion Matrix:\n",
      "[[726  12]\n",
      " [ 29  16]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       738\n",
      "           1       0.57      0.36      0.44        45\n",
      "\n",
      "    accuracy                           0.95       783\n",
      "   macro avg       0.77      0.67      0.71       783\n",
      "weighted avg       0.94      0.95      0.94       783\n",
      "\n",
      "\n",
      "---- GaussianNB ----\n",
      "Accuracy: 0.6334610472541508\n",
      "Confusion Matrix:\n",
      "[[453 285]\n",
      " [  2  43]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.61      0.76       738\n",
      "           1       0.13      0.96      0.23        45\n",
      "\n",
      "    accuracy                           0.63       783\n",
      "   macro avg       0.56      0.78      0.49       783\n",
      "weighted avg       0.95      0.63      0.73       783\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "cla_models_info = [\n",
    "    (\"Logistic Regression\", \"cla_lr_y_test\"),\n",
    "    (\"Decision Tree\", \"cla_dt_y_test\"),\n",
    "    (\"SVM\", \"cla_svm_y_test\"),\n",
    "    (\"Random Forest\", \"cla_rf_y_test\"),\n",
    "    (\"KNN\", \"cla_knn_y_test\"),\n",
    "    (\"GaussianNB\", \"cla_nb_y_test\")\n",
    "]\n",
    "\n",
    "for model_name, y_test_var_name in cla_models_info:\n",
    "    y_test_var = globals()[y_test_var_name]\n",
    "\n",
    "    accuracy = accuracy_score(y_test_c, y_test_var)\n",
    "    conf_matrix = confusion_matrix(y_test_c, y_test_var)\n",
    "    class_report = classification_report(y_test_c, y_test_var)\n",
    "\n",
    "    print(f\"---- {model_name} ----\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 105.6073 - mean_squared_error: 105.6073 - val_loss: 78.3660 - val_mean_squared_error: 78.3660\n",
      "Epoch 2/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 64.0862 - mean_squared_error: 64.0862 - val_loss: 45.2039 - val_mean_squared_error: 45.2039\n",
      "Epoch 3/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 22.0494 - mean_squared_error: 22.0494 - val_loss: 26.7301 - val_mean_squared_error: 26.7301\n",
      "Epoch 4/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 13.8849 - mean_squared_error: 13.8849 - val_loss: 18.4198 - val_mean_squared_error: 18.4198\n",
      "Epoch 5/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 10.6568 - mean_squared_error: 10.6568 - val_loss: 14.9646 - val_mean_squared_error: 14.9646\n",
      "Epoch 6/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 10.8603 - mean_squared_error: 10.8603 - val_loss: 13.4979 - val_mean_squared_error: 13.4979\n",
      "Epoch 7/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 9.8196 - mean_squared_error: 9.8196 - val_loss: 12.7807 - val_mean_squared_error: 12.7807\n",
      "Epoch 8/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 9.8301 - mean_squared_error: 9.8301 - val_loss: 12.7059 - val_mean_squared_error: 12.7059\n",
      "Epoch 9/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 10.2331 - mean_squared_error: 10.2331 - val_loss: 12.5547 - val_mean_squared_error: 12.5547\n",
      "Epoch 10/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.0616 - mean_squared_error: 10.0616 - val_loss: 12.3083 - val_mean_squared_error: 12.3083\n",
      "Epoch 11/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 9.6656 - mean_squared_error: 9.6656 - val_loss: 12.2264 - val_mean_squared_error: 12.2264\n",
      "Epoch 12/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 9.4231 - mean_squared_error: 9.4231 - val_loss: 12.2139 - val_mean_squared_error: 12.2139\n",
      "Epoch 13/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 10.0767 - mean_squared_error: 10.0767 - val_loss: 12.1812 - val_mean_squared_error: 12.1812\n",
      "Epoch 14/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 9.5215 - mean_squared_error: 9.5215 - val_loss: 12.1193 - val_mean_squared_error: 12.1193\n",
      "Epoch 15/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 9.0084 - mean_squared_error: 9.0084 - val_loss: 12.0470 - val_mean_squared_error: 12.0470\n",
      "Epoch 16/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 9.2028 - mean_squared_error: 9.2028 - val_loss: 11.9750 - val_mean_squared_error: 11.9750\n",
      "Epoch 17/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 9.0135 - mean_squared_error: 9.0135 - val_loss: 12.0905 - val_mean_squared_error: 12.0905\n",
      "Epoch 18/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 9.1371 - mean_squared_error: 9.1371 - val_loss: 12.0469 - val_mean_squared_error: 12.0469\n",
      "Epoch 19/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - loss: 8.9991 - mean_squared_error: 8.9991 - val_loss: 12.1506 - val_mean_squared_error: 12.1506\n",
      "Epoch 20/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 8.2680 - mean_squared_error: 8.2680 - val_loss: 12.1294 - val_mean_squared_error: 12.1294\n",
      "Epoch 21/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 8.8887 - mean_squared_error: 8.8887 - val_loss: 12.0699 - val_mean_squared_error: 12.0699\n",
      "Epoch 22/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 8.7331 - mean_squared_error: 8.7331 - val_loss: 12.0934 - val_mean_squared_error: 12.0934\n",
      "Epoch 23/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 9.0108 - mean_squared_error: 9.0108 - val_loss: 12.2233 - val_mean_squared_error: 12.2233\n",
      "Epoch 24/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 8.2853 - mean_squared_error: 8.2853 - val_loss: 12.2509 - val_mean_squared_error: 12.2509\n",
      "Epoch 25/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 8.3613 - mean_squared_error: 8.3613 - val_loss: 12.2725 - val_mean_squared_error: 12.2725\n",
      "Epoch 26/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 8.7720 - mean_squared_error: 8.7720 - val_loss: 12.3276 - val_mean_squared_error: 12.3276\n",
      "Epoch 27/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 8.7769 - mean_squared_error: 8.7769 - val_loss: 12.3423 - val_mean_squared_error: 12.3423\n",
      "Epoch 28/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 8.9585 - mean_squared_error: 8.9585 - val_loss: 12.3987 - val_mean_squared_error: 12.3987\n",
      "Epoch 29/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 8.7693 - mean_squared_error: 8.7693 - val_loss: 12.3313 - val_mean_squared_error: 12.3313\n",
      "Epoch 30/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 8.4076 - mean_squared_error: 8.4076 - val_loss: 12.5010 - val_mean_squared_error: 12.5010\n",
      "Epoch 31/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 8.4499 - mean_squared_error: 8.4499 - val_loss: 12.4429 - val_mean_squared_error: 12.4429\n",
      "Epoch 32/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 8.7411 - mean_squared_error: 8.7411 - val_loss: 12.5054 - val_mean_squared_error: 12.5054\n",
      "Epoch 33/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 8.3655 - mean_squared_error: 8.3655 - val_loss: 12.5715 - val_mean_squared_error: 12.5715\n",
      "Epoch 34/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 8.7444 - mean_squared_error: 8.7444 - val_loss: 12.5703 - val_mean_squared_error: 12.5703\n",
      "Epoch 35/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 8.0649 - mean_squared_error: 8.0649 - val_loss: 12.7341 - val_mean_squared_error: 12.7341\n",
      "Epoch 36/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 8.0439 - mean_squared_error: 8.0439 - val_loss: 12.5756 - val_mean_squared_error: 12.5756\n",
      "Epoch 37/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 8.3817 - mean_squared_error: 8.3817 - val_loss: 12.6425 - val_mean_squared_error: 12.6425\n",
      "Epoch 38/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 7.9559 - mean_squared_error: 7.9559 - val_loss: 12.7583 - val_mean_squared_error: 12.7583\n",
      "Epoch 39/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 8.2936 - mean_squared_error: 8.2936 - val_loss: 12.7295 - val_mean_squared_error: 12.7295\n",
      "Epoch 40/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 8.0419 - mean_squared_error: 8.0419 - val_loss: 12.8000 - val_mean_squared_error: 12.8000\n",
      "Epoch 41/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 7.8079 - mean_squared_error: 7.8079 - val_loss: 12.7910 - val_mean_squared_error: 12.7910\n",
      "Epoch 42/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 8.2135 - mean_squared_error: 8.2135 - val_loss: 12.9105 - val_mean_squared_error: 12.9105\n",
      "Epoch 43/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 8.1180 - mean_squared_error: 8.1180 - val_loss: 12.9975 - val_mean_squared_error: 12.9975\n",
      "Epoch 44/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 8.3232 - mean_squared_error: 8.3232 - val_loss: 12.8445 - val_mean_squared_error: 12.8445\n",
      "Epoch 45/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 7.6837 - mean_squared_error: 7.6837 - val_loss: 12.7607 - val_mean_squared_error: 12.7607\n",
      "Epoch 46/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 8.3055 - mean_squared_error: 8.3055 - val_loss: 12.9283 - val_mean_squared_error: 12.9283\n",
      "Epoch 47/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 8.0321 - mean_squared_error: 8.0321 - val_loss: 12.7890 - val_mean_squared_error: 12.7890\n",
      "Epoch 48/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 8.6830 - mean_squared_error: 8.6830 - val_loss: 13.0262 - val_mean_squared_error: 13.0262\n",
      "Epoch 49/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 8.2042 - mean_squared_error: 8.2042 - val_loss: 13.1795 - val_mean_squared_error: 13.1795\n",
      "Epoch 50/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.3414 - mean_squared_error: 8.3414 - val_loss: 13.0566 - val_mean_squared_error: 13.0566\n",
      "Epoch 51/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.0472 - mean_squared_error: 8.0472 - val_loss: 13.0105 - val_mean_squared_error: 13.0105\n",
      "Epoch 52/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 7.5789 - mean_squared_error: 7.5789 - val_loss: 12.9698 - val_mean_squared_error: 12.9698\n",
      "Epoch 53/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 8.2904 - mean_squared_error: 8.2904 - val_loss: 12.9824 - val_mean_squared_error: 12.9824\n",
      "Epoch 54/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 8.2394 - mean_squared_error: 8.2394 - val_loss: 13.0524 - val_mean_squared_error: 13.0524\n",
      "Epoch 55/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 7.9717 - mean_squared_error: 7.9717 - val_loss: 13.1320 - val_mean_squared_error: 13.1320\n",
      "Epoch 56/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 7.7277 - mean_squared_error: 7.7277 - val_loss: 13.1672 - val_mean_squared_error: 13.1672\n",
      "Epoch 57/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 8.4910 - mean_squared_error: 8.4910 - val_loss: 13.1607 - val_mean_squared_error: 13.1607\n",
      "Epoch 58/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 7.9931 - mean_squared_error: 7.9931 - val_loss: 13.0540 - val_mean_squared_error: 13.0540\n",
      "Epoch 59/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 7.8023 - mean_squared_error: 7.8023 - val_loss: 13.3494 - val_mean_squared_error: 13.3494\n",
      "Epoch 60/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6349 - mean_squared_error: 7.6349 - val_loss: 13.1998 - val_mean_squared_error: 13.1998\n",
      "Epoch 61/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 7.8833 - mean_squared_error: 7.8833 - val_loss: 13.2602 - val_mean_squared_error: 13.2602\n",
      "Epoch 62/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 7.5064 - mean_squared_error: 7.5064 - val_loss: 13.1405 - val_mean_squared_error: 13.1405\n",
      "Epoch 63/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 7.9486 - mean_squared_error: 7.9486 - val_loss: 13.2767 - val_mean_squared_error: 13.2767\n",
      "Epoch 64/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 8.4546 - mean_squared_error: 8.4546 - val_loss: 13.3092 - val_mean_squared_error: 13.3092\n",
      "Epoch 65/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 7.6097 - mean_squared_error: 7.6097 - val_loss: 13.3470 - val_mean_squared_error: 13.3470\n",
      "Epoch 66/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 7.2669 - mean_squared_error: 7.2669 - val_loss: 13.1760 - val_mean_squared_error: 13.1760\n",
      "Epoch 67/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 8.0588 - mean_squared_error: 8.0588 - val_loss: 13.3127 - val_mean_squared_error: 13.3127\n",
      "Epoch 68/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 7.5778 - mean_squared_error: 7.5778 - val_loss: 13.2709 - val_mean_squared_error: 13.2709\n",
      "Epoch 69/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 7.8143 - mean_squared_error: 7.8143 - val_loss: 13.2561 - val_mean_squared_error: 13.2561\n",
      "Epoch 70/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 7.8308 - mean_squared_error: 7.8308 - val_loss: 13.3503 - val_mean_squared_error: 13.3503\n",
      "Epoch 71/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 7.9207 - mean_squared_error: 7.9207 - val_loss: 13.4394 - val_mean_squared_error: 13.4394\n",
      "Epoch 72/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 7.3301 - mean_squared_error: 7.3301 - val_loss: 13.4550 - val_mean_squared_error: 13.4550\n",
      "Epoch 73/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 7.4224 - mean_squared_error: 7.4224 - val_loss: 13.3261 - val_mean_squared_error: 13.3261\n",
      "Epoch 74/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 7.6498 - mean_squared_error: 7.6498 - val_loss: 13.2454 - val_mean_squared_error: 13.2454\n",
      "Epoch 75/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 7.5495 - mean_squared_error: 7.5495 - val_loss: 13.3419 - val_mean_squared_error: 13.3419\n",
      "Epoch 76/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 7.4572 - mean_squared_error: 7.4572 - val_loss: 13.5655 - val_mean_squared_error: 13.5655\n",
      "Epoch 77/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 7.5305 - mean_squared_error: 7.5305 - val_loss: 13.4062 - val_mean_squared_error: 13.4062\n",
      "Epoch 78/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 7.9748 - mean_squared_error: 7.9748 - val_loss: 13.4976 - val_mean_squared_error: 13.4976\n",
      "Epoch 79/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 7.4841 - mean_squared_error: 7.4841 - val_loss: 13.5252 - val_mean_squared_error: 13.5252\n",
      "Epoch 80/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 7.4876 - mean_squared_error: 7.4876 - val_loss: 13.4534 - val_mean_squared_error: 13.4534\n",
      "Epoch 81/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 7.4866 - mean_squared_error: 7.4866 - val_loss: 13.5464 - val_mean_squared_error: 13.5464\n",
      "Epoch 82/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 7.4392 - mean_squared_error: 7.4392 - val_loss: 13.4686 - val_mean_squared_error: 13.4686\n",
      "Epoch 83/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 7.2983 - mean_squared_error: 7.2983 - val_loss: 13.4615 - val_mean_squared_error: 13.4615\n",
      "Epoch 84/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 7.5324 - mean_squared_error: 7.5324 - val_loss: 13.5940 - val_mean_squared_error: 13.5940\n",
      "Epoch 85/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.3503 - mean_squared_error: 7.3503 - val_loss: 13.6996 - val_mean_squared_error: 13.6996\n",
      "Epoch 86/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 7.1557 - mean_squared_error: 7.1557 - val_loss: 13.6560 - val_mean_squared_error: 13.6560\n",
      "Epoch 87/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 8.3297 - mean_squared_error: 8.3297 - val_loss: 13.6948 - val_mean_squared_error: 13.6948\n",
      "Epoch 88/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 7.0291 - mean_squared_error: 7.0291 - val_loss: 13.5686 - val_mean_squared_error: 13.5686\n",
      "Epoch 89/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 7.7460 - mean_squared_error: 7.7460 - val_loss: 13.7249 - val_mean_squared_error: 13.7249\n",
      "Epoch 90/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 7.3801 - mean_squared_error: 7.3801 - val_loss: 13.7464 - val_mean_squared_error: 13.7464\n",
      "Epoch 91/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 7.4249 - mean_squared_error: 7.4249 - val_loss: 13.7567 - val_mean_squared_error: 13.7567\n",
      "Epoch 92/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 7.4031 - mean_squared_error: 7.4031 - val_loss: 13.8068 - val_mean_squared_error: 13.8068\n",
      "Epoch 93/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 6.9632 - mean_squared_error: 6.9632 - val_loss: 13.8158 - val_mean_squared_error: 13.8158\n",
      "Epoch 94/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 7.0726 - mean_squared_error: 7.0726 - val_loss: 13.8219 - val_mean_squared_error: 13.8219\n",
      "Epoch 95/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - loss: 7.7993 - mean_squared_error: 7.7993 - val_loss: 13.6998 - val_mean_squared_error: 13.6998\n",
      "Epoch 96/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 7.3028 - mean_squared_error: 7.3028 - val_loss: 13.7918 - val_mean_squared_error: 13.7918\n",
      "Epoch 97/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 7.4541 - mean_squared_error: 7.4541 - val_loss: 13.9026 - val_mean_squared_error: 13.9026\n",
      "Epoch 98/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 7.5935 - mean_squared_error: 7.5935 - val_loss: 13.7813 - val_mean_squared_error: 13.7813\n",
      "Epoch 99/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 7.5487 - mean_squared_error: 7.5487 - val_loss: 13.6844 - val_mean_squared_error: 13.6844\n",
      "Epoch 100/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 7.1852 - mean_squared_error: 7.1852 - val_loss: 13.9589 - val_mean_squared_error: 13.9589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30693e870>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dl_reg_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(146,)),  # Input layer with 146 features\n",
    "    tf.keras.layers.Dense(16, activation='relu'),  # Hidden layer with 32 neurons\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "dl_reg_model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "dl_reg_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "R² score on test set: 0.6236976635221939\n"
     ]
    }
   ],
   "source": [
    "dl_reg_y_pred = dl_reg_model.predict(X_test)\n",
    "dl_reg_r2 = r2_score(y_test, dl_reg_y_pred)\n",
    "print(f'R² score on test set: {dl_reg_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8708 - loss: 0.4721 - val_accuracy: 0.9441 - val_loss: 0.2359\n",
      "Epoch 2/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9414 - loss: 0.1811 - val_accuracy: 0.9464 - val_loss: 0.1629\n",
      "Epoch 3/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.9369 - loss: 0.1501 - val_accuracy: 0.9475 - val_loss: 0.1377\n",
      "Epoch 4/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.9454 - loss: 0.1297 - val_accuracy: 0.9609 - val_loss: 0.1242\n",
      "Epoch 5/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.9542 - loss: 0.1194 - val_accuracy: 0.9665 - val_loss: 0.1175\n",
      "Epoch 6/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.9529 - loss: 0.1151 - val_accuracy: 0.9687 - val_loss: 0.1124\n",
      "Epoch 7/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.9539 - loss: 0.1232 - val_accuracy: 0.9609 - val_loss: 0.1084\n",
      "Epoch 8/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9557 - loss: 0.1156 - val_accuracy: 0.9631 - val_loss: 0.1059\n",
      "Epoch 9/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.9532 - loss: 0.1085 - val_accuracy: 0.9676 - val_loss: 0.1041\n",
      "Epoch 10/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.9540 - loss: 0.1078 - val_accuracy: 0.9676 - val_loss: 0.1033\n",
      "Epoch 11/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.9545 - loss: 0.1103 - val_accuracy: 0.9698 - val_loss: 0.1035\n",
      "Epoch 12/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.9584 - loss: 0.1044 - val_accuracy: 0.9687 - val_loss: 0.1033\n",
      "Epoch 13/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.9543 - loss: 0.1005 - val_accuracy: 0.9687 - val_loss: 0.1007\n",
      "Epoch 14/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.9658 - loss: 0.0917 - val_accuracy: 0.9698 - val_loss: 0.0998\n",
      "Epoch 15/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.9589 - loss: 0.1009 - val_accuracy: 0.9721 - val_loss: 0.1019\n",
      "Epoch 16/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.9539 - loss: 0.0996 - val_accuracy: 0.9709 - val_loss: 0.1013\n",
      "Epoch 17/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.9628 - loss: 0.0933 - val_accuracy: 0.9709 - val_loss: 0.1008\n",
      "Epoch 18/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.9556 - loss: 0.1000 - val_accuracy: 0.9687 - val_loss: 0.1000\n",
      "Epoch 19/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.9589 - loss: 0.0890 - val_accuracy: 0.9687 - val_loss: 0.1003\n",
      "Epoch 20/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.9581 - loss: 0.0963 - val_accuracy: 0.9698 - val_loss: 0.1010\n",
      "Epoch 21/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.9621 - loss: 0.0880 - val_accuracy: 0.9631 - val_loss: 0.1120\n",
      "Epoch 22/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.9615 - loss: 0.0940 - val_accuracy: 0.9709 - val_loss: 0.1040\n",
      "Epoch 23/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.9633 - loss: 0.0894 - val_accuracy: 0.9709 - val_loss: 0.1019\n",
      "Epoch 24/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.9632 - loss: 0.0882 - val_accuracy: 0.9676 - val_loss: 0.1043\n",
      "Epoch 25/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9582 - loss: 0.0930 - val_accuracy: 0.9698 - val_loss: 0.1021\n",
      "Epoch 26/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9605 - loss: 0.0869 - val_accuracy: 0.9676 - val_loss: 0.1048\n",
      "Epoch 27/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.9658 - loss: 0.0784 - val_accuracy: 0.9687 - val_loss: 0.1040\n",
      "Epoch 28/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.9665 - loss: 0.0851 - val_accuracy: 0.9687 - val_loss: 0.1081\n",
      "Epoch 29/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9570 - loss: 0.0905 - val_accuracy: 0.9698 - val_loss: 0.1042\n",
      "Epoch 30/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.9640 - loss: 0.0862 - val_accuracy: 0.9687 - val_loss: 0.1051\n",
      "Epoch 31/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9654 - loss: 0.0813 - val_accuracy: 0.9676 - val_loss: 0.1076\n",
      "Epoch 32/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.9640 - loss: 0.0810 - val_accuracy: 0.9676 - val_loss: 0.1098\n",
      "Epoch 33/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.9677 - loss: 0.0768 - val_accuracy: 0.9676 - val_loss: 0.1087\n",
      "Epoch 34/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.9641 - loss: 0.0808 - val_accuracy: 0.9698 - val_loss: 0.1131\n",
      "Epoch 35/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9689 - loss: 0.0753 - val_accuracy: 0.9687 - val_loss: 0.1096\n",
      "Epoch 36/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9625 - loss: 0.0831 - val_accuracy: 0.9676 - val_loss: 0.1165\n",
      "Epoch 37/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.9656 - loss: 0.0807 - val_accuracy: 0.9665 - val_loss: 0.1131\n",
      "Epoch 38/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.9728 - loss: 0.0701 - val_accuracy: 0.9665 - val_loss: 0.1142\n",
      "Epoch 39/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.9683 - loss: 0.0804 - val_accuracy: 0.9654 - val_loss: 0.1191\n",
      "Epoch 40/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9679 - loss: 0.0767 - val_accuracy: 0.9687 - val_loss: 0.1176\n",
      "Epoch 41/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.9705 - loss: 0.0753 - val_accuracy: 0.9687 - val_loss: 0.1172\n",
      "Epoch 42/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.9709 - loss: 0.0754 - val_accuracy: 0.9687 - val_loss: 0.1189\n",
      "Epoch 43/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.9689 - loss: 0.0725 - val_accuracy: 0.9665 - val_loss: 0.1250\n",
      "Epoch 44/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.9702 - loss: 0.0703 - val_accuracy: 0.9665 - val_loss: 0.1249\n",
      "Epoch 45/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.9715 - loss: 0.0721 - val_accuracy: 0.9665 - val_loss: 0.1198\n",
      "Epoch 46/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.9735 - loss: 0.0627 - val_accuracy: 0.9665 - val_loss: 0.1227\n",
      "Epoch 47/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.9741 - loss: 0.0664 - val_accuracy: 0.9665 - val_loss: 0.1227\n",
      "Epoch 48/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.9713 - loss: 0.0722 - val_accuracy: 0.9654 - val_loss: 0.1271\n",
      "Epoch 49/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9717 - loss: 0.0687 - val_accuracy: 0.9676 - val_loss: 0.1301\n",
      "Epoch 50/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.9717 - loss: 0.0669 - val_accuracy: 0.9687 - val_loss: 0.1261\n",
      "Epoch 51/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.9678 - loss: 0.0708 - val_accuracy: 0.9642 - val_loss: 0.1392\n",
      "Epoch 52/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.9727 - loss: 0.0671 - val_accuracy: 0.9676 - val_loss: 0.1299\n",
      "Epoch 53/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.9771 - loss: 0.0635 - val_accuracy: 0.9687 - val_loss: 0.1290\n",
      "Epoch 54/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9750 - loss: 0.0695 - val_accuracy: 0.9654 - val_loss: 0.1338\n",
      "Epoch 55/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.9726 - loss: 0.0634 - val_accuracy: 0.9631 - val_loss: 0.1397\n",
      "Epoch 56/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.9727 - loss: 0.0631 - val_accuracy: 0.9676 - val_loss: 0.1366\n",
      "Epoch 57/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.9759 - loss: 0.0569 - val_accuracy: 0.9665 - val_loss: 0.1358\n",
      "Epoch 58/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.9761 - loss: 0.0596 - val_accuracy: 0.9642 - val_loss: 0.1408\n",
      "Epoch 59/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.9745 - loss: 0.0608 - val_accuracy: 0.9654 - val_loss: 0.1417\n",
      "Epoch 60/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.9771 - loss: 0.0552 - val_accuracy: 0.9654 - val_loss: 0.1448\n",
      "Epoch 61/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.9747 - loss: 0.0544 - val_accuracy: 0.9598 - val_loss: 0.1555\n",
      "Epoch 62/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9751 - loss: 0.0610 - val_accuracy: 0.9620 - val_loss: 0.1485\n",
      "Epoch 63/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.9775 - loss: 0.0562 - val_accuracy: 0.9642 - val_loss: 0.1469\n",
      "Epoch 64/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.9736 - loss: 0.0611 - val_accuracy: 0.9642 - val_loss: 0.1468\n",
      "Epoch 65/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.9786 - loss: 0.0566 - val_accuracy: 0.9620 - val_loss: 0.1531\n",
      "Epoch 66/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9793 - loss: 0.0547 - val_accuracy: 0.9609 - val_loss: 0.1548\n",
      "Epoch 67/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.9775 - loss: 0.0573 - val_accuracy: 0.9598 - val_loss: 0.1486\n",
      "Epoch 68/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.9721 - loss: 0.0587 - val_accuracy: 0.9598 - val_loss: 0.1520\n",
      "Epoch 69/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.9766 - loss: 0.0566 - val_accuracy: 0.9598 - val_loss: 0.1537\n",
      "Epoch 70/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9762 - loss: 0.0560 - val_accuracy: 0.9631 - val_loss: 0.1561\n",
      "Epoch 71/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.9819 - loss: 0.0461 - val_accuracy: 0.9553 - val_loss: 0.1655\n",
      "Epoch 72/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.9741 - loss: 0.0547 - val_accuracy: 0.9553 - val_loss: 0.1726\n",
      "Epoch 73/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.9795 - loss: 0.0543 - val_accuracy: 0.9598 - val_loss: 0.1712\n",
      "Epoch 74/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.9782 - loss: 0.0478 - val_accuracy: 0.9631 - val_loss: 0.1630\n",
      "Epoch 75/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.9778 - loss: 0.0508 - val_accuracy: 0.9598 - val_loss: 0.1626\n",
      "Epoch 76/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.9793 - loss: 0.0536 - val_accuracy: 0.9620 - val_loss: 0.1684\n",
      "Epoch 77/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.9855 - loss: 0.0473 - val_accuracy: 0.9575 - val_loss: 0.1750\n",
      "Epoch 78/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9762 - loss: 0.0555 - val_accuracy: 0.9575 - val_loss: 0.1693\n",
      "Epoch 79/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9803 - loss: 0.0513 - val_accuracy: 0.9609 - val_loss: 0.1736\n",
      "Epoch 80/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.9820 - loss: 0.0471 - val_accuracy: 0.9587 - val_loss: 0.1737\n",
      "Epoch 81/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.9851 - loss: 0.0487 - val_accuracy: 0.9620 - val_loss: 0.1744\n",
      "Epoch 82/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.9763 - loss: 0.0517 - val_accuracy: 0.9553 - val_loss: 0.1768\n",
      "Epoch 83/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9804 - loss: 0.0532 - val_accuracy: 0.9564 - val_loss: 0.1874\n",
      "Epoch 84/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9847 - loss: 0.0408 - val_accuracy: 0.9598 - val_loss: 0.1787\n",
      "Epoch 85/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.9824 - loss: 0.0480 - val_accuracy: 0.9531 - val_loss: 0.1924\n",
      "Epoch 86/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.9808 - loss: 0.0468 - val_accuracy: 0.9542 - val_loss: 0.1910\n",
      "Epoch 87/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.9795 - loss: 0.0521 - val_accuracy: 0.9598 - val_loss: 0.1865\n",
      "Epoch 88/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9800 - loss: 0.0476 - val_accuracy: 0.9575 - val_loss: 0.1913\n",
      "Epoch 89/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9831 - loss: 0.0459 - val_accuracy: 0.9575 - val_loss: 0.1881\n",
      "Epoch 90/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.9838 - loss: 0.0466 - val_accuracy: 0.9575 - val_loss: 0.1902\n",
      "Epoch 91/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.9819 - loss: 0.0431 - val_accuracy: 0.9575 - val_loss: 0.1862\n",
      "Epoch 92/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.9867 - loss: 0.0382 - val_accuracy: 0.9575 - val_loss: 0.1876\n",
      "Epoch 93/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.9858 - loss: 0.0456 - val_accuracy: 0.9520 - val_loss: 0.2007\n",
      "Epoch 94/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.9871 - loss: 0.0406 - val_accuracy: 0.9564 - val_loss: 0.1974\n",
      "Epoch 95/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.9854 - loss: 0.0409 - val_accuracy: 0.9575 - val_loss: 0.1986\n",
      "Epoch 96/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.9863 - loss: 0.0437 - val_accuracy: 0.9531 - val_loss: 0.2112\n",
      "Epoch 97/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.9831 - loss: 0.0464 - val_accuracy: 0.9598 - val_loss: 0.2094\n",
      "Epoch 98/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.9846 - loss: 0.0428 - val_accuracy: 0.9531 - val_loss: 0.2106\n",
      "Epoch 99/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.9849 - loss: 0.0425 - val_accuracy: 0.9531 - val_loss: 0.2095\n",
      "Epoch 100/100\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.9841 - loss: 0.0441 - val_accuracy: 0.9520 - val_loss: 0.2138\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.9279 - loss: 0.2557\n",
      "Test accuracy: 0.9284802079200745\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the model\n",
    "dl_cl_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(146,)),  # Input layer with 146 features\n",
    "    tf.keras.layers.Dense(32, activation='relu'),  # Additional hidden layer with 64 neurons\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer for classification\n",
    "])\n",
    "\n",
    "dl_cl_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "dl_cl_model.fit(X_train, y_train_c, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = dl_cl_model.evaluate(X_test, y_test_c)\n",
    "\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Accuracy: 0.9323116219667944\n",
      "Confusion Matrix:\n",
      "[[722  16]\n",
      " [ 37   8]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       738\n",
      "           1       0.33      0.18      0.23        45\n",
      "\n",
      "    accuracy                           0.93       783\n",
      "   macro avg       0.64      0.58      0.60       783\n",
      "weighted avg       0.92      0.93      0.92       783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "dl_cl_y_pred_prob = dl_cl_model.predict(X_test)\n",
    "\n",
    "dl_cl_y_pred = (dl_cl_y_pred_prob > 0.6).astype(\"int32\")\n",
    "\n",
    "dl_cl_accuracy = accuracy_score(y_test_c, dl_cl_y_pred)\n",
    "dl_cl_conf_matrix = confusion_matrix(y_test_c, dl_cl_y_pred)\n",
    "dl_cl_class_report = classification_report(y_test_c, dl_cl_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {dl_cl_accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(dl_cl_conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(dl_cl_class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
