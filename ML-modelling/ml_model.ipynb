{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid</th>\n",
       "      <th>position</th>\n",
       "      <th>year</th>\n",
       "      <th>round</th>\n",
       "      <th>driver_age</th>\n",
       "      <th>driver_experience</th>\n",
       "      <th>driver_constructor_experience</th>\n",
       "      <th>driver_points</th>\n",
       "      <th>driver_standing</th>\n",
       "      <th>constructor_points</th>\n",
       "      <th>...</th>\n",
       "      <th>constructor_mclaren</th>\n",
       "      <th>constructor_mercedes</th>\n",
       "      <th>constructor_racing_point</th>\n",
       "      <th>constructor_rb</th>\n",
       "      <th>constructor_red_bull</th>\n",
       "      <th>constructor_renault</th>\n",
       "      <th>constructor_sauber</th>\n",
       "      <th>constructor_toro_rosso</th>\n",
       "      <th>constructor_virgin</th>\n",
       "      <th>constructor_williams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>116</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid  position  year  round  driver_age  driver_experience  \\\n",
       "0     3       1.0  2010      1          28                140   \n",
       "1     2       2.0  2010      1          28                116   \n",
       "2     4       3.0  2010      1          25                 52   \n",
       "3     1       4.0  2010      1          22                 43   \n",
       "4     5       5.0  2010      1          24                 70   \n",
       "\n",
       "   driver_constructor_experience  driver_points  driver_standing  \\\n",
       "0                              0            0.0              0.0   \n",
       "1                             63            0.0              0.0   \n",
       "2                             52            0.0              0.0   \n",
       "3                             17            0.0              0.0   \n",
       "4                              0            0.0              0.0   \n",
       "\n",
       "   constructor_points  ...  constructor_mclaren  constructor_mercedes  \\\n",
       "0                 0.0  ...                False                 False   \n",
       "1                 0.0  ...                False                 False   \n",
       "2                 0.0  ...                 True                 False   \n",
       "3                 0.0  ...                False                 False   \n",
       "4                 0.0  ...                False                  True   \n",
       "\n",
       "   constructor_racing_point  constructor_rb  constructor_red_bull  \\\n",
       "0                     False           False                 False   \n",
       "1                     False           False                 False   \n",
       "2                     False           False                 False   \n",
       "3                     False           False                  True   \n",
       "4                     False           False                 False   \n",
       "\n",
       "   constructor_renault  constructor_sauber  constructor_toro_rosso  \\\n",
       "0                False               False                   False   \n",
       "1                False               False                   False   \n",
       "2                False               False                   False   \n",
       "3                False               False                   False   \n",
       "4                False               False                   False   \n",
       "\n",
       "   constructor_virgin  constructor_williams  \n",
       "0               False                 False  \n",
       "1               False                 False  \n",
       "2               False                 False  \n",
       "3               False                 False  \n",
       "4               False                 False  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data-collection/final_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Here the test data needs to be whole races, not random entries from different races\\n# Will do 3 races per season as test sets\\ntest_races_per_year = 3\\n\\n# Create a train-test split based on races\\nunique_races = df[[\\'year\\', \\'round\\']].drop_duplicates()\\ntest_races = unique_races.groupby(\\'year\\').sample(n=test_races_per_year, random_state=42)\\n\\n# Mark test races in the dataset\\ndf[\\'is_test\\'] = df[[\\'year\\', \\'round\\']].apply(\\n    lambda x: tuple(x) in test_races.itertuples(index=False, name=None), axis=1\\n)\\n\\n# Split the data\\ntrain_df = df[df[\\'is_test\\'] == False]\\ntest_df = df[df[\\'is_test\\'] == True]\\n\\ntrain_df = train_df.drop(columns=[\\'is_test\\'])\\ntest_df = test_df.drop(columns=[\\'is_test\\'])\\n\\nprint(f\"Training set size: {len(train_df)}, Testing set size: {len(test_df)}\")\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Here the test data needs to be whole races, not random entries from different races\n",
    "# Will do 3 races per season as test sets\n",
    "test_races_per_year = 3\n",
    "\n",
    "# Create a train-test split based on races\n",
    "unique_races = df[['year', 'round']].drop_duplicates()\n",
    "test_races = unique_races.groupby('year').sample(n=test_races_per_year, random_state=42)\n",
    "\n",
    "# Mark test races in the dataset\n",
    "df['is_test'] = df[['year', 'round']].apply(\n",
    "    lambda x: tuple(x) in test_races.itertuples(index=False, name=None), axis=1\n",
    ")\n",
    "\n",
    "# Split the data\n",
    "train_df = df[df['is_test'] == False]\n",
    "test_df = df[df['is_test'] == True]\n",
    "\n",
    "train_df = train_df.drop(columns=['is_test'])\n",
    "test_df = test_df.drop(columns=['is_test'])\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}, Testing set size: {len(test_df)}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.copy()\n",
    "test_df = pd.read_csv('../Data-collection/df_2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features: (4883, 146), Testing Features: (421, 146)\n",
      "Training Target: (4883,), Testing Target: (421,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.drop(columns=['position'])\n",
    "X_test = test_df.drop(columns=['position'])\n",
    "\n",
    "y_train = train_df['position']\n",
    "y_test = test_df['position']\n",
    "\n",
    "print(f\"Training Features: {X_train.shape}, Testing Features: {X_test.shape}\")\n",
    "print(f\"Training Target: {y_train.shape}, Testing Target: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numerical columns for scaling\n",
    "numerical_columns = [\n",
    "    'grid', 'driver_age', 'driver_experience', 'driver_constructor_experience',\n",
    "    'driver_points', 'driver_standing', 'constructor_points', \n",
    "    'constructor_standing', 'driver_wins', 'constructor_wins', 'circuit_danger', \n",
    "    'year', 'round'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "\n",
    "# conver one-hot-encoding columns from True/False to 1/0\n",
    "all_columns = X_train.columns.tolist()\n",
    "one_hot_columns = [col for col in all_columns if col not in numerical_columns]\n",
    "\n",
    "X_train[one_hot_columns] = X_train[one_hot_columns].astype(int)\n",
    "X_test[one_hot_columns] = X_test[one_hot_columns].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasar test df\n",
    "\n",
    "def process_round(df, scaler, trained_model):    \n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "    \n",
    "    # Convert one-hot encoding columns from boolean to int\n",
    "    one_hot_columns = [col for col in df.columns if df[col].dtype == 'bool']\n",
    "    df[one_hot_columns] = df[one_hot_columns].astype(int)\n",
    "    \n",
    "    X_current_round = df.drop(columns=['position'])\n",
    "\n",
    "    predictions_df = pd.DataFrame({'predicted_position': trained_model.predict(X_current_round)}) # Make predictions\n",
    "    predictions_df.index = df.index # Ensure the indices align for merging\n",
    "    df = pd.concat([df, predictions_df], axis=1) # Merge predictions back into the original DataFrame\n",
    "    \n",
    "    # Identify the predicted winner\n",
    "    predicted_winner_idx = df['predicted_position'].idxmin()\n",
    "    predicted_winner_row = df.loc[predicted_winner_idx]\n",
    "    predicted_winner_name = next(col for col in one_hot_columns if predicted_winner_row[col] == 1)\n",
    "    predicted_winner_name = predicted_winner_name.replace(\"driver_\", \"\").replace(\"_\", \" \").title()\n",
    "    predicted_winner_name = predicted_winner_name.split()[-1]\n",
    "    predicted_position = predicted_winner_row['predicted_position']\n",
    "    \n",
    "    # Identify the actual winner\n",
    "    actual_winner_row = df[df['position'] == 1.0]\n",
    "    if not actual_winner_row.empty:\n",
    "        actual_winner_name = next(col for col in one_hot_columns if actual_winner_row.iloc[0][col] == 1)\n",
    "        actual_winner_name = actual_winner_name.replace(\"driver_\", \"\").replace(\"_\", \" \").title()\n",
    "        actual_winner_name = actual_winner_name.split()[-1]\n",
    "    else:\n",
    "        actual_winner_name = \"--\"\n",
    "    \n",
    "    return {\n",
    "        'predicted_winner': predicted_winner_name,\n",
    "        'predicted_position': predicted_position,\n",
    "        'actual_winner': actual_winner_name\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasar test df\n",
    "\n",
    "def process_all_rounds(df, trained_model):\n",
    "    scaler = StandardScaler()\n",
    "    unique_years = df['year'].unique()\n",
    "    results = []\n",
    "    \n",
    "    for year_number in unique_years:\n",
    "        df_current_year = df[df['year'] == year_number].copy()\n",
    "        unique_rounds = df_current_year['round'].unique()\n",
    "        for round_number in unique_rounds:\n",
    "            df_current_round = df_current_year[df_current_year['round'] == round_number].copy()\n",
    "            result = process_round(df_current_round, scaler, trained_model)\n",
    "            result['round'] = round_number\n",
    "            result['year'] = year_number\n",
    "            results.append(result)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df[['round'] + [col for col in results_df.columns if col != 'round']]\n",
    "    results_df = results_df[['year'] + [col for col in results_df.columns if col != 'year']]\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pasar df de la funcion anterior\n",
    "\n",
    "def model_accuracy (df, model_name):\n",
    "    accuracy = {}\n",
    "    accuracy['model_name'] = model_name\n",
    "\n",
    "    new_df = df['predicted_winner'] == df['actual_winner']\n",
    "    accuracy['accuracy'] = new_df.mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasar test_df\n",
    "\n",
    "def test_all_models (df, trained_models):\n",
    "\n",
    "    accuracy = []\n",
    "\n",
    "    for model_name, model_var_name in trained_models:\n",
    "        model_var = globals()[model_var_name]\n",
    "        model_test_df = []\n",
    "\n",
    "        model_test_df = process_all_rounds(df, model_var)\n",
    "        accuracy.append(model_accuracy(model_test_df, model_name))\n",
    "\n",
    "    accuracy_df = pd.DataFrame(accuracy)\n",
    "\n",
    "    return accuracy_df        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg_lr_model = LinearRegression()\n",
    "reg_lr_model.fit(X_train, y_train)\n",
    "reg_lr_y_test = reg_lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg_rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "reg_rf_model.fit(X_train, y_train)\n",
    "reg_rf_y_test = reg_rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "reg_svm_model = SVR(kernel='linear') \n",
    "reg_svm_model.fit(X_train, y_train)\n",
    "reg_svm_y_test = reg_svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "reg_dt_model = DecisionTreeRegressor()\n",
    "reg_dt_model.fit(X_train, y_train)\n",
    "reg_dt_y_test = reg_dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "reg_knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "reg_knn_model.fit(X_train, y_train)\n",
    "reg_knn_y_test = reg_knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "reg_lasso_model = Lasso(alpha=0.1) \n",
    "reg_lasso_model.fit(X_train, y_train)\n",
    "reg_lasso_y_test = reg_lasso_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_c = y_train.copy()\n",
    "y_test_c = y_test.copy()\n",
    "y_train_c = y_train_c.apply(lambda x: 1 if x == 1 else 0)\n",
    "y_test_c = y_test_c.apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "cla_lr_model = LogisticRegression()\n",
    "cla_lr_model.fit(X_train, y_train_c)\n",
    "cla_lr_y_test = cla_lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "cla_dt_model = DecisionTreeClassifier()\n",
    "cla_dt_model.fit(X_train, y_train_c)\n",
    "cla_dt_y_test = cla_dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "cla_svm_model = SVC(kernel='linear')\n",
    "cla_svm_model.fit(X_train, y_train_c)\n",
    "cla_svm_y_test = cla_svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "cla_rf_model = RandomForestClassifier(n_estimators=100)\n",
    "cla_rf_model.fit(X_train, y_train_c)\n",
    "cla_rf_y_test = cla_rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "cla_knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "cla_knn_model.fit(X_train, y_train_c)\n",
    "cla_knn_y_test = cla_knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "cla_nb_model = GaussianNB()\n",
    "cla_nb_model.fit(X_train, y_train_c)\n",
    "cla_nb_y_test = cla_nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Logistic Regression ----\n",
      "Accuracy: 0.9453681710213777\n",
      "Confusion Matrix:\n",
      "[[390   8]\n",
      " [ 15   8]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       398\n",
      "           1       0.50      0.35      0.41        23\n",
      "\n",
      "    accuracy                           0.95       421\n",
      "   macro avg       0.73      0.66      0.69       421\n",
      "weighted avg       0.94      0.95      0.94       421\n",
      "\n",
      "\n",
      "---- Decision Tree ----\n",
      "Accuracy: 0.9263657957244655\n",
      "Confusion Matrix:\n",
      "[[379  19]\n",
      " [ 12  11]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       398\n",
      "           1       0.37      0.48      0.42        23\n",
      "\n",
      "    accuracy                           0.93       421\n",
      "   macro avg       0.67      0.72      0.69       421\n",
      "weighted avg       0.94      0.93      0.93       421\n",
      "\n",
      "\n",
      "---- SVM ----\n",
      "Accuracy: 0.9406175771971497\n",
      "Confusion Matrix:\n",
      "[[389   9]\n",
      " [ 16   7]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       398\n",
      "           1       0.44      0.30      0.36        23\n",
      "\n",
      "    accuracy                           0.94       421\n",
      "   macro avg       0.70      0.64      0.66       421\n",
      "weighted avg       0.93      0.94      0.94       421\n",
      "\n",
      "\n",
      "---- Random Forest ----\n",
      "Accuracy: 0.9287410926365796\n",
      "Confusion Matrix:\n",
      "[[384  14]\n",
      " [ 16   7]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       398\n",
      "           1       0.33      0.30      0.32        23\n",
      "\n",
      "    accuracy                           0.93       421\n",
      "   macro avg       0.65      0.63      0.64       421\n",
      "weighted avg       0.93      0.93      0.93       421\n",
      "\n",
      "\n",
      "---- KNN ----\n",
      "Accuracy: 0.9334916864608076\n",
      "Confusion Matrix:\n",
      "[[384  14]\n",
      " [ 14   9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       398\n",
      "           1       0.39      0.39      0.39        23\n",
      "\n",
      "    accuracy                           0.93       421\n",
      "   macro avg       0.68      0.68      0.68       421\n",
      "weighted avg       0.93      0.93      0.93       421\n",
      "\n",
      "\n",
      "---- GaussianNB ----\n",
      "Accuracy: 0.5700712589073634\n",
      "Confusion Matrix:\n",
      "[[223 175]\n",
      " [  6  17]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.56      0.71       398\n",
      "           1       0.09      0.74      0.16        23\n",
      "\n",
      "    accuracy                           0.57       421\n",
      "   macro avg       0.53      0.65      0.43       421\n",
      "weighted avg       0.93      0.57      0.68       421\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "cla_models_info = [\n",
    "    (\"Logistic Regression\", \"cla_lr_y_test\"),\n",
    "    (\"Decision Tree\", \"cla_dt_y_test\"),\n",
    "    (\"SVM\", \"cla_svm_y_test\"),\n",
    "    (\"Random Forest\", \"cla_rf_y_test\"),\n",
    "    (\"KNN\", \"cla_knn_y_test\"),\n",
    "    (\"GaussianNB\", \"cla_nb_y_test\")\n",
    "]\n",
    "\n",
    "for model_name, y_test_var_name in cla_models_info:\n",
    "    y_test_var = globals()[y_test_var_name]\n",
    "\n",
    "    accuracy = accuracy_score(y_test_c, y_test_var)\n",
    "    conf_matrix = confusion_matrix(y_test_c, y_test_var)\n",
    "    class_report = classification_report(y_test_c, y_test_var)\n",
    "\n",
    "    print(f\"---- {model_name} ----\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 103.9004 - mean_squared_error: 103.9004 - val_loss: 75.1477 - val_mean_squared_error: 75.1477\n",
      "Epoch 2/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 49.1682 - mean_squared_error: 49.1682 - val_loss: 45.7265 - val_mean_squared_error: 45.7265\n",
      "Epoch 3/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.1109 - mean_squared_error: 22.1109 - val_loss: 34.3231 - val_mean_squared_error: 34.3231\n",
      "Epoch 4/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16.4175 - mean_squared_error: 16.4175 - val_loss: 27.4625 - val_mean_squared_error: 27.4625\n",
      "Epoch 5/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.4498 - mean_squared_error: 13.4498 - val_loss: 22.3087 - val_mean_squared_error: 22.3087\n",
      "Epoch 6/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.7206 - mean_squared_error: 11.7206 - val_loss: 18.7559 - val_mean_squared_error: 18.7559\n",
      "Epoch 7/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.3827 - mean_squared_error: 10.3827 - val_loss: 16.5682 - val_mean_squared_error: 16.5682\n",
      "Epoch 8/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.6510 - mean_squared_error: 10.6510 - val_loss: 15.0390 - val_mean_squared_error: 15.0390\n",
      "Epoch 9/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.9805 - mean_squared_error: 9.9805 - val_loss: 14.4811 - val_mean_squared_error: 14.4811\n",
      "Epoch 10/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.0237 - mean_squared_error: 9.0237 - val_loss: 13.9237 - val_mean_squared_error: 13.9237\n",
      "Epoch 11/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.6075 - mean_squared_error: 9.6075 - val_loss: 13.6711 - val_mean_squared_error: 13.6711\n",
      "Epoch 12/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.4587 - mean_squared_error: 9.4587 - val_loss: 13.5220 - val_mean_squared_error: 13.5220\n",
      "Epoch 13/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.3768 - mean_squared_error: 9.3768 - val_loss: 13.4476 - val_mean_squared_error: 13.4476\n",
      "Epoch 14/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.9885 - mean_squared_error: 8.9885 - val_loss: 13.2036 - val_mean_squared_error: 13.2036\n",
      "Epoch 15/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.2765 - mean_squared_error: 9.2765 - val_loss: 13.1361 - val_mean_squared_error: 13.1361\n",
      "Epoch 16/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.8698 - mean_squared_error: 8.8698 - val_loss: 12.9421 - val_mean_squared_error: 12.9421\n",
      "Epoch 17/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.5170 - mean_squared_error: 9.5170 - val_loss: 12.9054 - val_mean_squared_error: 12.9054\n",
      "Epoch 18/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.9271 - mean_squared_error: 8.9271 - val_loss: 12.7415 - val_mean_squared_error: 12.7415\n",
      "Epoch 19/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.5643 - mean_squared_error: 8.5643 - val_loss: 12.7385 - val_mean_squared_error: 12.7385\n",
      "Epoch 20/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.1115 - mean_squared_error: 9.1115 - val_loss: 12.5921 - val_mean_squared_error: 12.5921\n",
      "Epoch 21/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.3364 - mean_squared_error: 9.3364 - val_loss: 12.5856 - val_mean_squared_error: 12.5856\n",
      "Epoch 22/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.7929 - mean_squared_error: 8.7929 - val_loss: 12.6752 - val_mean_squared_error: 12.6752\n",
      "Epoch 23/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4448 - mean_squared_error: 8.4448 - val_loss: 12.4642 - val_mean_squared_error: 12.4642\n",
      "Epoch 24/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.6629 - mean_squared_error: 8.6629 - val_loss: 12.5572 - val_mean_squared_error: 12.5572\n",
      "Epoch 25/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.7976 - mean_squared_error: 8.7976 - val_loss: 12.5072 - val_mean_squared_error: 12.5072\n",
      "Epoch 26/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7965 - mean_squared_error: 7.7965 - val_loss: 12.3126 - val_mean_squared_error: 12.3126\n",
      "Epoch 27/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.2015 - mean_squared_error: 8.2015 - val_loss: 12.3542 - val_mean_squared_error: 12.3542\n",
      "Epoch 28/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.5391 - mean_squared_error: 8.5391 - val_loss: 12.5555 - val_mean_squared_error: 12.5555\n",
      "Epoch 29/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.1096 - mean_squared_error: 8.1096 - val_loss: 12.5157 - val_mean_squared_error: 12.5157\n",
      "Epoch 30/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.0367 - mean_squared_error: 8.0367 - val_loss: 12.4642 - val_mean_squared_error: 12.4642\n",
      "Epoch 31/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.2595 - mean_squared_error: 8.2595 - val_loss: 12.4896 - val_mean_squared_error: 12.4896\n",
      "Epoch 32/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7632 - mean_squared_error: 8.7632 - val_loss: 12.5329 - val_mean_squared_error: 12.5329\n",
      "Epoch 33/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8953 - mean_squared_error: 8.8953 - val_loss: 12.4388 - val_mean_squared_error: 12.4388\n",
      "Epoch 34/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9045 - mean_squared_error: 7.9045 - val_loss: 12.4659 - val_mean_squared_error: 12.4659\n",
      "Epoch 35/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.0353 - mean_squared_error: 8.0353 - val_loss: 12.5525 - val_mean_squared_error: 12.5525\n",
      "Epoch 36/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.1832 - mean_squared_error: 8.1832 - val_loss: 12.4562 - val_mean_squared_error: 12.4562\n",
      "Epoch 37/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.0705 - mean_squared_error: 8.0705 - val_loss: 12.6076 - val_mean_squared_error: 12.6076\n",
      "Epoch 38/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.9873 - mean_squared_error: 7.9873 - val_loss: 12.6240 - val_mean_squared_error: 12.6240\n",
      "Epoch 39/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.8619 - mean_squared_error: 7.8619 - val_loss: 12.5952 - val_mean_squared_error: 12.5952\n",
      "Epoch 40/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.9909 - mean_squared_error: 7.9909 - val_loss: 12.6282 - val_mean_squared_error: 12.6282\n",
      "Epoch 41/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.8267 - mean_squared_error: 7.8267 - val_loss: 12.6149 - val_mean_squared_error: 12.6149\n",
      "Epoch 42/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.8557 - mean_squared_error: 7.8557 - val_loss: 12.7243 - val_mean_squared_error: 12.7243\n",
      "Epoch 43/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7719 - mean_squared_error: 7.7719 - val_loss: 12.7413 - val_mean_squared_error: 12.7413\n",
      "Epoch 44/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7951 - mean_squared_error: 7.7951 - val_loss: 12.7910 - val_mean_squared_error: 12.7910\n",
      "Epoch 45/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7117 - mean_squared_error: 7.7117 - val_loss: 12.7925 - val_mean_squared_error: 12.7925\n",
      "Epoch 46/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6749 - mean_squared_error: 7.6749 - val_loss: 12.8721 - val_mean_squared_error: 12.8721\n",
      "Epoch 47/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.8947 - mean_squared_error: 7.8947 - val_loss: 13.0841 - val_mean_squared_error: 13.0841\n",
      "Epoch 48/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7973 - mean_squared_error: 7.7973 - val_loss: 12.9938 - val_mean_squared_error: 12.9938\n",
      "Epoch 49/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6228 - mean_squared_error: 7.6228 - val_loss: 12.8442 - val_mean_squared_error: 12.8442\n",
      "Epoch 50/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4259 - mean_squared_error: 7.4259 - val_loss: 13.0850 - val_mean_squared_error: 13.0850\n",
      "Epoch 51/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7492 - mean_squared_error: 7.7492 - val_loss: 13.0288 - val_mean_squared_error: 13.0288\n",
      "Epoch 52/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.2430 - mean_squared_error: 8.2430 - val_loss: 13.0357 - val_mean_squared_error: 13.0357\n",
      "Epoch 53/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4399 - mean_squared_error: 7.4399 - val_loss: 13.0526 - val_mean_squared_error: 13.0526\n",
      "Epoch 54/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.1925 - mean_squared_error: 7.1925 - val_loss: 13.1041 - val_mean_squared_error: 13.1041\n",
      "Epoch 55/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6758 - mean_squared_error: 7.6758 - val_loss: 13.1789 - val_mean_squared_error: 13.1789\n",
      "Epoch 56/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.1539 - mean_squared_error: 7.1539 - val_loss: 13.2032 - val_mean_squared_error: 13.2032\n",
      "Epoch 57/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5986 - mean_squared_error: 7.5986 - val_loss: 13.2980 - val_mean_squared_error: 13.2980\n",
      "Epoch 58/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7801 - mean_squared_error: 7.7801 - val_loss: 13.4445 - val_mean_squared_error: 13.4445\n",
      "Epoch 59/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4986 - mean_squared_error: 7.4986 - val_loss: 13.2726 - val_mean_squared_error: 13.2726\n",
      "Epoch 60/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.9899 - mean_squared_error: 7.9899 - val_loss: 13.3744 - val_mean_squared_error: 13.3744\n",
      "Epoch 61/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4183 - mean_squared_error: 7.4183 - val_loss: 13.3570 - val_mean_squared_error: 13.3570\n",
      "Epoch 62/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.9570 - mean_squared_error: 6.9570 - val_loss: 13.3247 - val_mean_squared_error: 13.3247\n",
      "Epoch 63/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4250 - mean_squared_error: 7.4250 - val_loss: 13.5136 - val_mean_squared_error: 13.5136\n",
      "Epoch 64/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2933 - mean_squared_error: 7.2933 - val_loss: 13.5000 - val_mean_squared_error: 13.5000\n",
      "Epoch 65/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5484 - mean_squared_error: 7.5484 - val_loss: 13.5063 - val_mean_squared_error: 13.5063\n",
      "Epoch 66/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.3593 - mean_squared_error: 7.3593 - val_loss: 13.6676 - val_mean_squared_error: 13.6676\n",
      "Epoch 67/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.3037 - mean_squared_error: 7.3037 - val_loss: 13.5293 - val_mean_squared_error: 13.5293\n",
      "Epoch 68/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2087 - mean_squared_error: 7.2087 - val_loss: 13.6458 - val_mean_squared_error: 13.6458\n",
      "Epoch 69/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7049 - mean_squared_error: 7.7049 - val_loss: 13.7095 - val_mean_squared_error: 13.7095\n",
      "Epoch 70/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2373 - mean_squared_error: 7.2373 - val_loss: 13.8568 - val_mean_squared_error: 13.8568\n",
      "Epoch 71/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.9207 - mean_squared_error: 6.9207 - val_loss: 13.6834 - val_mean_squared_error: 13.6834\n",
      "Epoch 72/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.1577 - mean_squared_error: 7.1577 - val_loss: 13.7706 - val_mean_squared_error: 13.7706\n",
      "Epoch 73/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.9600 - mean_squared_error: 6.9600 - val_loss: 13.7962 - val_mean_squared_error: 13.7962\n",
      "Epoch 74/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4575 - mean_squared_error: 7.4575 - val_loss: 13.8712 - val_mean_squared_error: 13.8712\n",
      "Epoch 75/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2358 - mean_squared_error: 7.2358 - val_loss: 13.9333 - val_mean_squared_error: 13.9333\n",
      "Epoch 76/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6629 - mean_squared_error: 7.6629 - val_loss: 14.0056 - val_mean_squared_error: 14.0056\n",
      "Epoch 77/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.3807 - mean_squared_error: 7.3807 - val_loss: 13.9702 - val_mean_squared_error: 13.9702\n",
      "Epoch 78/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2915 - mean_squared_error: 7.2915 - val_loss: 14.0688 - val_mean_squared_error: 14.0688\n",
      "Epoch 79/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.3773 - mean_squared_error: 7.3773 - val_loss: 13.9699 - val_mean_squared_error: 13.9699\n",
      "Epoch 80/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.9891 - mean_squared_error: 6.9891 - val_loss: 13.9754 - val_mean_squared_error: 13.9754\n",
      "Epoch 81/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.1017 - mean_squared_error: 7.1017 - val_loss: 14.1550 - val_mean_squared_error: 14.1550\n",
      "Epoch 82/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.9561 - mean_squared_error: 6.9561 - val_loss: 14.3975 - val_mean_squared_error: 14.3975\n",
      "Epoch 83/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2536 - mean_squared_error: 7.2536 - val_loss: 14.2211 - val_mean_squared_error: 14.2211\n",
      "Epoch 84/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5916 - mean_squared_error: 7.5916 - val_loss: 14.2288 - val_mean_squared_error: 14.2288\n",
      "Epoch 85/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2744 - mean_squared_error: 7.2744 - val_loss: 14.2689 - val_mean_squared_error: 14.2689\n",
      "Epoch 86/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2822 - mean_squared_error: 7.2822 - val_loss: 14.3332 - val_mean_squared_error: 14.3332\n",
      "Epoch 87/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.8194 - mean_squared_error: 7.8194 - val_loss: 14.2572 - val_mean_squared_error: 14.2572\n",
      "Epoch 88/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.9578 - mean_squared_error: 6.9578 - val_loss: 14.3827 - val_mean_squared_error: 14.3827\n",
      "Epoch 89/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.0067 - mean_squared_error: 7.0067 - val_loss: 14.3695 - val_mean_squared_error: 14.3695\n",
      "Epoch 90/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.0068 - mean_squared_error: 7.0068 - val_loss: 14.4212 - val_mean_squared_error: 14.4212\n",
      "Epoch 91/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.8863 - mean_squared_error: 6.8863 - val_loss: 14.2679 - val_mean_squared_error: 14.2679\n",
      "Epoch 92/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.7272 - mean_squared_error: 6.7272 - val_loss: 14.6419 - val_mean_squared_error: 14.6419\n",
      "Epoch 93/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.8979 - mean_squared_error: 6.8979 - val_loss: 14.5000 - val_mean_squared_error: 14.5000\n",
      "Epoch 94/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1059 - mean_squared_error: 7.1059 - val_loss: 14.5307 - val_mean_squared_error: 14.5307\n",
      "Epoch 95/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.0745 - mean_squared_error: 7.0745 - val_loss: 14.5081 - val_mean_squared_error: 14.5081\n",
      "Epoch 96/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.9709 - mean_squared_error: 6.9709 - val_loss: 14.5451 - val_mean_squared_error: 14.5451\n",
      "Epoch 97/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.1150 - mean_squared_error: 7.1150 - val_loss: 14.4691 - val_mean_squared_error: 14.4691\n",
      "Epoch 98/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.6357 - mean_squared_error: 6.6357 - val_loss: 14.4795 - val_mean_squared_error: 14.4795\n",
      "Epoch 99/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.9222 - mean_squared_error: 6.9222 - val_loss: 14.6217 - val_mean_squared_error: 14.6217\n",
      "Epoch 100/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.4003 - mean_squared_error: 6.4003 - val_loss: 14.6771 - val_mean_squared_error: 14.6771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x11ce3b380>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dl_reg_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(146,)),  # Input layer with 146 features\n",
    "    tf.keras.layers.Dense(16, activation='relu'),  # Hidden layer with 32 neurons\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "dl_reg_model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "dl_reg_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "R² score on test set: 0.30914355677548644\n"
     ]
    }
   ],
   "source": [
    "dl_reg_y_pred = dl_reg_model.predict(X_test)\n",
    "dl_reg_r2 = r2_score(y_test, dl_reg_y_pred)\n",
    "print(f'R² score on test set: {dl_reg_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6337 - loss: 0.6031 - val_accuracy: 0.9519 - val_loss: 0.3393\n",
      "Epoch 2/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9417 - loss: 0.2036 - val_accuracy: 0.9488 - val_loss: 0.2105\n",
      "Epoch 3/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.1532 - val_accuracy: 0.9417 - val_loss: 0.1699\n",
      "Epoch 4/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9507 - loss: 0.1181 - val_accuracy: 0.9509 - val_loss: 0.1480\n",
      "Epoch 5/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9469 - loss: 0.1253 - val_accuracy: 0.9550 - val_loss: 0.1361\n",
      "Epoch 6/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9518 - loss: 0.1192 - val_accuracy: 0.9652 - val_loss: 0.1194\n",
      "Epoch 7/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1203 - val_accuracy: 0.9672 - val_loss: 0.1116\n",
      "Epoch 8/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9537 - loss: 0.1179 - val_accuracy: 0.9652 - val_loss: 0.1111\n",
      "Epoch 9/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9515 - loss: 0.1165 - val_accuracy: 0.9652 - val_loss: 0.1089\n",
      "Epoch 10/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9579 - loss: 0.1053 - val_accuracy: 0.9662 - val_loss: 0.1072\n",
      "Epoch 11/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.1077 - val_accuracy: 0.9672 - val_loss: 0.1045\n",
      "Epoch 12/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1098 - val_accuracy: 0.9652 - val_loss: 0.1041\n",
      "Epoch 13/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9592 - loss: 0.1040 - val_accuracy: 0.9662 - val_loss: 0.1037\n",
      "Epoch 14/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.0964 - val_accuracy: 0.9672 - val_loss: 0.1021\n",
      "Epoch 15/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9547 - loss: 0.0991 - val_accuracy: 0.9683 - val_loss: 0.1018\n",
      "Epoch 16/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9593 - loss: 0.1027 - val_accuracy: 0.9672 - val_loss: 0.1002\n",
      "Epoch 17/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9524 - loss: 0.0993 - val_accuracy: 0.9672 - val_loss: 0.1010\n",
      "Epoch 18/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9548 - loss: 0.0998 - val_accuracy: 0.9642 - val_loss: 0.1026\n",
      "Epoch 19/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9551 - loss: 0.1126 - val_accuracy: 0.9693 - val_loss: 0.1000\n",
      "Epoch 20/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9533 - loss: 0.1039 - val_accuracy: 0.9652 - val_loss: 0.1000\n",
      "Epoch 21/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9563 - loss: 0.1008 - val_accuracy: 0.9652 - val_loss: 0.1007\n",
      "Epoch 22/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9550 - loss: 0.1010 - val_accuracy: 0.9632 - val_loss: 0.1022\n",
      "Epoch 23/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9628 - loss: 0.0845 - val_accuracy: 0.9652 - val_loss: 0.1005\n",
      "Epoch 24/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9562 - loss: 0.0957 - val_accuracy: 0.9632 - val_loss: 0.1033\n",
      "Epoch 25/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9590 - loss: 0.0904 - val_accuracy: 0.9632 - val_loss: 0.1014\n",
      "Epoch 26/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9585 - loss: 0.0909 - val_accuracy: 0.9611 - val_loss: 0.1010\n",
      "Epoch 27/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9654 - loss: 0.0873 - val_accuracy: 0.9642 - val_loss: 0.1008\n",
      "Epoch 28/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.0936 - val_accuracy: 0.9570 - val_loss: 0.1089\n",
      "Epoch 29/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9629 - loss: 0.0863 - val_accuracy: 0.9570 - val_loss: 0.1040\n",
      "Epoch 30/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9617 - loss: 0.0922 - val_accuracy: 0.9601 - val_loss: 0.1036\n",
      "Epoch 31/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9634 - loss: 0.0834 - val_accuracy: 0.9580 - val_loss: 0.1043\n",
      "Epoch 32/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9637 - loss: 0.0892 - val_accuracy: 0.9591 - val_loss: 0.1033\n",
      "Epoch 33/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9598 - loss: 0.0927 - val_accuracy: 0.9591 - val_loss: 0.1083\n",
      "Epoch 34/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.0859 - val_accuracy: 0.9601 - val_loss: 0.1059\n",
      "Epoch 35/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9654 - loss: 0.0815 - val_accuracy: 0.9591 - val_loss: 0.1045\n",
      "Epoch 36/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9636 - loss: 0.0895 - val_accuracy: 0.9591 - val_loss: 0.1048\n",
      "Epoch 37/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9608 - loss: 0.0910 - val_accuracy: 0.9560 - val_loss: 0.1077\n",
      "Epoch 38/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9706 - loss: 0.0744 - val_accuracy: 0.9560 - val_loss: 0.1067\n",
      "Epoch 39/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9653 - loss: 0.0841 - val_accuracy: 0.9591 - val_loss: 0.1062\n",
      "Epoch 40/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9638 - loss: 0.0840 - val_accuracy: 0.9601 - val_loss: 0.1052\n",
      "Epoch 41/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9646 - loss: 0.0847 - val_accuracy: 0.9570 - val_loss: 0.1076\n",
      "Epoch 42/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9647 - loss: 0.0821 - val_accuracy: 0.9621 - val_loss: 0.1081\n",
      "Epoch 43/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.0863 - val_accuracy: 0.9570 - val_loss: 0.1084\n",
      "Epoch 44/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9639 - loss: 0.0824 - val_accuracy: 0.9529 - val_loss: 0.1135\n",
      "Epoch 45/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.0813 - val_accuracy: 0.9570 - val_loss: 0.1089\n",
      "Epoch 46/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9622 - loss: 0.0834 - val_accuracy: 0.9550 - val_loss: 0.1093\n",
      "Epoch 47/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9613 - loss: 0.0863 - val_accuracy: 0.9529 - val_loss: 0.1124\n",
      "Epoch 48/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.0788 - val_accuracy: 0.9498 - val_loss: 0.1224\n",
      "Epoch 49/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9665 - loss: 0.0804 - val_accuracy: 0.9580 - val_loss: 0.1111\n",
      "Epoch 50/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.0774 - val_accuracy: 0.9601 - val_loss: 0.1109\n",
      "Epoch 51/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9670 - loss: 0.0784 - val_accuracy: 0.9580 - val_loss: 0.1121\n",
      "Epoch 52/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.0783 - val_accuracy: 0.9539 - val_loss: 0.1157\n",
      "Epoch 53/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9697 - loss: 0.0743 - val_accuracy: 0.9550 - val_loss: 0.1146\n",
      "Epoch 54/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9730 - loss: 0.0671 - val_accuracy: 0.9529 - val_loss: 0.1195\n",
      "Epoch 55/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9679 - loss: 0.0750 - val_accuracy: 0.9529 - val_loss: 0.1189\n",
      "Epoch 56/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9679 - loss: 0.0785 - val_accuracy: 0.9519 - val_loss: 0.1181\n",
      "Epoch 57/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9605 - loss: 0.0855 - val_accuracy: 0.9529 - val_loss: 0.1175\n",
      "Epoch 58/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9684 - loss: 0.0729 - val_accuracy: 0.9519 - val_loss: 0.1182\n",
      "Epoch 59/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9693 - loss: 0.0719 - val_accuracy: 0.9539 - val_loss: 0.1185\n",
      "Epoch 60/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9720 - loss: 0.0721 - val_accuracy: 0.9529 - val_loss: 0.1198\n",
      "Epoch 61/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9719 - loss: 0.0712 - val_accuracy: 0.9591 - val_loss: 0.1214\n",
      "Epoch 62/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9685 - loss: 0.0751 - val_accuracy: 0.9570 - val_loss: 0.1202\n",
      "Epoch 63/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9686 - loss: 0.0701 - val_accuracy: 0.9509 - val_loss: 0.1273\n",
      "Epoch 64/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9730 - loss: 0.0666 - val_accuracy: 0.9580 - val_loss: 0.1211\n",
      "Epoch 65/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.0782 - val_accuracy: 0.9529 - val_loss: 0.1242\n",
      "Epoch 66/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9723 - loss: 0.0699 - val_accuracy: 0.9591 - val_loss: 0.1251\n",
      "Epoch 67/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9726 - loss: 0.0642 - val_accuracy: 0.9519 - val_loss: 0.1242\n",
      "Epoch 68/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9687 - loss: 0.0729 - val_accuracy: 0.9539 - val_loss: 0.1270\n",
      "Epoch 69/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9753 - loss: 0.0671 - val_accuracy: 0.9570 - val_loss: 0.1250\n",
      "Epoch 70/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9730 - loss: 0.0699 - val_accuracy: 0.9570 - val_loss: 0.1277\n",
      "Epoch 71/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9670 - loss: 0.0748 - val_accuracy: 0.9498 - val_loss: 0.1287\n",
      "Epoch 72/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9737 - loss: 0.0628 - val_accuracy: 0.9539 - val_loss: 0.1298\n",
      "Epoch 73/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9698 - loss: 0.0744 - val_accuracy: 0.9529 - val_loss: 0.1317\n",
      "Epoch 74/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9758 - loss: 0.0637 - val_accuracy: 0.9580 - val_loss: 0.1291\n",
      "Epoch 75/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9790 - loss: 0.0613 - val_accuracy: 0.9529 - val_loss: 0.1345\n",
      "Epoch 76/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9740 - loss: 0.0640 - val_accuracy: 0.9570 - val_loss: 0.1330\n",
      "Epoch 77/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9734 - loss: 0.0638 - val_accuracy: 0.9560 - val_loss: 0.1333\n",
      "Epoch 78/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9771 - loss: 0.0596 - val_accuracy: 0.9591 - val_loss: 0.1338\n",
      "Epoch 79/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9746 - loss: 0.0602 - val_accuracy: 0.9550 - val_loss: 0.1350\n",
      "Epoch 80/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9748 - loss: 0.0631 - val_accuracy: 0.9498 - val_loss: 0.1398\n",
      "Epoch 81/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9725 - loss: 0.0647 - val_accuracy: 0.9570 - val_loss: 0.1365\n",
      "Epoch 82/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9737 - loss: 0.0627 - val_accuracy: 0.9519 - val_loss: 0.1405\n",
      "Epoch 83/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9741 - loss: 0.0663 - val_accuracy: 0.9509 - val_loss: 0.1415\n",
      "Epoch 84/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9755 - loss: 0.0611 - val_accuracy: 0.9478 - val_loss: 0.1431\n",
      "Epoch 85/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9747 - loss: 0.0645 - val_accuracy: 0.9560 - val_loss: 0.1401\n",
      "Epoch 86/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9796 - loss: 0.0576 - val_accuracy: 0.9550 - val_loss: 0.1383\n",
      "Epoch 87/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9770 - loss: 0.0609 - val_accuracy: 0.9550 - val_loss: 0.1418\n",
      "Epoch 88/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9794 - loss: 0.0588 - val_accuracy: 0.9570 - val_loss: 0.1441\n",
      "Epoch 89/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9788 - loss: 0.0559 - val_accuracy: 0.9468 - val_loss: 0.1494\n",
      "Epoch 90/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9764 - loss: 0.0616 - val_accuracy: 0.9529 - val_loss: 0.1466\n",
      "Epoch 91/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9794 - loss: 0.0582 - val_accuracy: 0.9519 - val_loss: 0.1457\n",
      "Epoch 92/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9743 - loss: 0.0614 - val_accuracy: 0.9509 - val_loss: 0.1498\n",
      "Epoch 93/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9737 - loss: 0.0622 - val_accuracy: 0.9437 - val_loss: 0.1555\n",
      "Epoch 94/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9762 - loss: 0.0570 - val_accuracy: 0.9539 - val_loss: 0.1487\n",
      "Epoch 95/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9741 - loss: 0.0597 - val_accuracy: 0.9498 - val_loss: 0.1529\n",
      "Epoch 96/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9755 - loss: 0.0563 - val_accuracy: 0.9488 - val_loss: 0.1532\n",
      "Epoch 97/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9778 - loss: 0.0586 - val_accuracy: 0.9539 - val_loss: 0.1514\n",
      "Epoch 98/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9715 - loss: 0.0670 - val_accuracy: 0.9560 - val_loss: 0.1537\n",
      "Epoch 99/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9764 - loss: 0.0596 - val_accuracy: 0.9550 - val_loss: 0.1541\n",
      "Epoch 100/100\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9753 - loss: 0.0565 - val_accuracy: 0.9529 - val_loss: 0.1570\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.2109 \n",
      "Test accuracy: 0.9287410974502563\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the model\n",
    "dl_cl_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(146,)),  # Input layer with 146 features\n",
    "    tf.keras.layers.Dense(32, activation='relu'),  # Additional hidden layer with 64 neurons\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer for classification\n",
    "])\n",
    "\n",
    "dl_cl_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "dl_cl_model.fit(X_train, y_train_c, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = dl_cl_model.evaluate(X_test, y_test_c)\n",
    "\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Accuracy: 0.9334916864608076\n",
      "Confusion Matrix:\n",
      "[[389   9]\n",
      " [ 19   4]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       398\n",
      "           1       0.31      0.17      0.22        23\n",
      "\n",
      "    accuracy                           0.93       421\n",
      "   macro avg       0.63      0.58      0.59       421\n",
      "weighted avg       0.92      0.93      0.92       421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "dl_cl_y_pred_prob = dl_cl_model.predict(X_test)\n",
    "\n",
    "dl_cl_y_pred = (dl_cl_y_pred_prob > 0.6).astype(\"int32\")\n",
    "\n",
    "dl_cl_accuracy = accuracy_score(y_test_c, dl_cl_y_pred)\n",
    "dl_cl_conf_matrix = confusion_matrix(y_test_c, dl_cl_y_pred)\n",
    "dl_cl_class_report = classification_report(y_test_c, dl_cl_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {dl_cl_accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(dl_cl_conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(dl_cl_class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          model_name  accuracy\n",
      "0  Linear Regression  0.041667\n",
      "1      Random Forest  0.375000\n",
      "2                SVM  0.375000\n",
      "3      Decision Tree  0.375000\n",
      "4                KNN  0.208333\n",
      "5              Lasso  0.416667\n"
     ]
    }
   ],
   "source": [
    "reg_models = [\n",
    "    (\"Linear Regression\", \"reg_lr_model\"),\n",
    "    (\"Random Forest\", \"reg_rf_model\"),\n",
    "    (\"SVM\", \"reg_svm_model\"),\n",
    "    (\"Decision Tree\", \"reg_dt_model\"),\n",
    "    (\"KNN\", \"reg_knn_model\"),\n",
    "    (\"Lasso\", \"reg_lasso_model\") # TODO: Adapt Deep Learning: dl_reg_model\n",
    "]\n",
    "\n",
    "reg_models_accuracy = test_all_models(test_df, reg_models)\n",
    "\n",
    "print(reg_models_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " year  round predicted_winner  predicted_position actual_winner\n",
      " 2024      1       Verstappen            5.738987    Verstappen\n",
      " 2024      2       Verstappen            1.167036    Verstappen\n",
      " 2024      3          Leclerc            2.600225            --\n",
      " 2024      4       Verstappen            2.214198    Verstappen\n",
      " 2024      5       Verstappen            1.891564    Verstappen\n",
      " 2024      6       Verstappen            1.340561        Norris\n",
      " 2024      7       Verstappen            1.395040    Verstappen\n",
      " 2024      8          Leclerc            2.935386       Leclerc\n",
      " 2024      9       Verstappen            2.114960    Verstappen\n",
      " 2024     10       Verstappen            1.834022    Verstappen\n",
      " 2024     11       Verstappen            1.050475       Russell\n",
      " 2024     12       Verstappen            2.571257      Hamilton\n",
      " 2024     13       Verstappen            2.012855       Piastri\n",
      " 2024     14          Leclerc            3.396601      Hamilton\n",
      " 2024     15       Verstappen            1.919905        Norris\n",
      " 2024     16           Norris            2.957017       Leclerc\n",
      " 2024     17       Verstappen            4.261481       Piastri\n",
      " 2024     18       Verstappen            2.558091        Norris\n",
      " 2024     19       Verstappen            2.036238       Leclerc\n",
      " 2024     20       Verstappen            3.141685         Sainz\n",
      " 2024     21           Norris            3.088998    Verstappen\n",
      " 2024     22            Sainz            4.459500       Russell\n",
      " 2024     23       Verstappen            3.353842    Verstappen\n",
      " 2024     24           Norris            2.760444        Norris\n"
     ]
    }
   ],
   "source": [
    "results_df = process_all_rounds(test_df, reg_lasso_model) # TODO: choose the better model dynamically\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cla_models = [\n",
    "    (\"Logistic Regression\", \"cla_lr_model\"),\n",
    "    (\"Decision Tree\", \"cla_dt_model\"),\n",
    "    (\"SVM\", \"cla_svm_model\"),\n",
    "    (\"Random Forest\", \"cla_rf_model\"),\n",
    "    (\"KNN\", \"cla_knn_model\"),\n",
    "    (\"GaussianNB\", \"cla_nb_model\"),\n",
    "]\n",
    "\n",
    "df_test_c = test_df.copy()\n",
    "df_test_c['position'] = df_test_c['position'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "reg_models_info = [\n",
    "    (\"Linear Regression\", \"reg_lr_y_test\"),\n",
    "    (\"Random Forest\", \"reg_rf_y_test\"),\n",
    "    (\"SVM\", \"reg_svm_y_test\"),\n",
    "    (\"Decision Tree\", \"reg_dt_y_test\"),\n",
    "    (\"KNN\", \"reg_knn_y_test\"),\n",
    "    (\"Lasso\", \"reg_lasso_y_test\"),\n",
    "    (\"Deep Learning\", \"dl_reg_y_pred\")\n",
    "]\n",
    "\n",
    "reg_r2_scores = []\n",
    "reg_model_names = []\n",
    "\n",
    "for model_name, y_test_var_name in reg_models_info:\n",
    "    y_test_var = globals()[y_test_var_name]\n",
    "\n",
    "    r2 = r2_score(y_test, y_test_var)\n",
    "    reg_r2_scores.append(r2)\n",
    "    reg_model_names.append(model_name)\n",
    "\n",
    "plt.bar(reg_model_names, reg_r2_scores)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('Regression Models')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "cla_models_info = [\n",
    "    (\"Logistic Regression\", \"cla_lr_y_test\"),\n",
    "    (\"Decision Tree\", \"cla_dt_y_test\"),\n",
    "    (\"SVM\", \"cla_svm_y_test\"),\n",
    "    (\"Random Forest\", \"cla_rf_y_test\"),\n",
    "    (\"KNN\", \"cla_knn_y_test\"),\n",
    "    (\"GaussianNB\", \"cla_nb_y_test\"),\n",
    "    (\"Deep Learning\", \"dl_cl_y_pred\")\n",
    "]\n",
    "\n",
    "cl_f1_scores = []\n",
    "cl_model_names = []\n",
    "\n",
    "for model_name, y_test_var_name in cla_models_info:\n",
    "    y_test_var = globals()[y_test_var_name]\n",
    "\n",
    "    f1 = f1_score(y_test_c, y_test_var, pos_label=1)\n",
    "    cl_f1_scores.append(f1)\n",
    "    cl_model_names.append(model_name)\n",
    "    \n",
    "\n",
    "plt.bar(cl_model_names, cl_f1_scores)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Classification Models')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(reg_rf_model, 'trained_model.pkl') # TODO: use the best model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
